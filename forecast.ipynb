{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800bb330-193d-4f51-926f-65531d8fc65b",
   "metadata": {},
   "source": [
    "# üìà –ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ –∏–∑ Excel-—Ñ–∞–π–ª–∞\n",
    "\n",
    "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –∏ —Å—Ç—Ä–æ–∏—Ç –ø—Ä–æ–≥–Ω–æ–∑ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ Holt-Winters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ade19-81cb-4e30-bc71-a5bbf01c60d9",
   "metadata": {},
   "source": [
    "## üìÇ –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774a684b-7559-4bd5-8efe-c18768e21a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm  # –ò–º–ø–æ—Ä—Ç tqdm –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042a10e-3ef8-441a-ad10-5e47c06f4ad6",
   "metadata": {},
   "source": [
    "## üìä –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843e7b35-7cfe-41cb-af47-85f134cd291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–∞–Ω–Ω—ã–º–∏\n",
    "file_path = r\"C:\\\\Users\\\\User\\\\Dropbox\\\\00 –ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã. –ê–Ω–∞–ª–∏—Ç–∏–∫–∞\\\\02 - –û—Ç—á–µ—Ç—ã\\\\01 - –†—É—Å–ª–∞–Ω (–ú–°2)\\\\04 - –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ —Å–ø—Ä–æ—Å—É\\\\–ü—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å –ú–°1.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b351d177-6d48-4da2-b68f-8532d0452cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–∏\n",
    "df[\"–î–∞—Ç–∞\"] = pd.to_datetime(df[\"–ì–æ–¥\"].astype(str) + \"-\" + df[\"–ú–µ—Å—è—Ü\"].astype(str) + \"-01\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç\n",
    "full_date_range = pd.date_range(start=df[\"–î–∞—Ç–∞\"].min(), end=df[\"–î–∞—Ç–∞\"].max(), freq=\"MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2063e480-1249-4223-a2f2-0efdcfbdfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –º–µ—Å—è—Ü—ã –Ω—É–ª—è–º–∏\n",
    "df_full = (\n",
    "    df.set_index(\"–î–∞—Ç–∞\")\n",
    "    .groupby([\"–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞\", \"–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü\", \"–ö–æ–¥\", \"–ê—Ä—Ç–∏–∫—É–ª\", \"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\", \"–ì—Ä—É–ø–ø–∞\", \"–¶–µ–Ω–∞, —Ä—É–±.\", \"–í–µ—Å, –∫–≥.\", \"–í–∏–¥ —Å—ã—Ä—å—è\"])\n",
    "    .apply(lambda x: x.reindex(full_date_range, fill_value=0))\n",
    ")\n",
    "\n",
    "# –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å\n",
    "df_full = df_full.drop([\"–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞\", \"–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü\", \"–ö–æ–¥\", \"–ê—Ä—Ç–∏–∫—É–ª\", \"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\", \"–ì—Ä—É–ø–ø–∞\", \"–¶–µ–Ω–∞, —Ä—É–±.\", \"–í–µ—Å, –∫–≥.\", \"–í–∏–¥ —Å—ã—Ä—å—è\"],axis=1).reset_index()\n",
    "df_full = df_full.rename(columns={\"level_9\":\"–î–∞—Ç–∞\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b01d578a-d3aa-4a67-83f5-c25d302fb477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞', '–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü', '–ö–æ–¥', '–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ',\n",
       "       '–ì—Ä—É–ø–ø–∞', '–¶–µ–Ω–∞, —Ä—É–±.', '–í–µ—Å, –∫–≥.', '–í–∏–¥ —Å—ã—Ä—å—è', '–î–∞—Ç–∞', '–ì–æ–¥',\n",
       "       '–ö–≤–∞—Ä—Ç–∞–ª', '–ú–µ—Å—è—Ü', '–û—Ç–≥—Ä—É–∂–µ–Ω–æ, —à—Ç.', '–û–±–æ—Ä–æ—Ç, —Ä—É–±.'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "421b9c7e-aa04-47aa-b86a-e520f5dc25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞, –∫–≤–∞—Ä—Ç–∞–ª–∞ –∏ –º–µ—Å—è—Ü–∞ –∏–∑ –¥–∞—Ç—ã\n",
    "df_full[\"–ì–æ–¥\"] = df_full[\"–î–∞—Ç–∞\"].dt.year\n",
    "df_full[\"–ö–≤–∞—Ä—Ç–∞–ª\"] = ((df_full[\"–î–∞—Ç–∞\"].dt.month - 1) // 3 + 1)\n",
    "df_full[\"–ú–µ—Å—è—Ü\"] = df_full[\"–î–∞—Ç–∞\"].dt.month\n",
    "\n",
    "# –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "df_full = df_full[[\"–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞\", \"–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü\", \"–ì—Ä—É–ø–ø–∞\", \"–ö–æ–¥\", \"–ê—Ä—Ç–∏–∫—É–ª\", \"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\", \"–î–∞—Ç–∞\", \"–ì–æ–¥\", \"–ö–≤–∞—Ä—Ç–∞–ª\", \"–ú–µ—Å—è—Ü\", \"–û—Ç–≥—Ä—É–∂–µ–Ω–æ, —à—Ç.\", \"–¶–µ–Ω–∞, —Ä—É–±.\", \"–í–µ—Å, –∫–≥.\", \"–í–∏–¥ —Å—ã—Ä—å—è\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd2898-534e-48ef-b3b7-dc79205457f5",
   "metadata": {},
   "source": [
    "## üîÆ Holt-Winters –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1daf967e-0361-4311-916c-fa1e1ea5dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "alphas = betas = gammas = np.arange(0.20, 1, 0.10)\n",
    "abg = list(itertools.product(alphas, betas, gammas))\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "def tes_optimizer(ts, abg, step=6):\n",
    "    \"\"\"\n",
    "    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç—Ä–æ–π–Ω–æ–≥–æ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è.\n",
    "    \n",
    "    ts: pd.Series - –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥\n",
    "    abg: list - –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "    step: int - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "    \"\"\"\n",
    "    best_alpha, best_beta, best_gamma, best_mae = None, None, None, float(\"inf\")\n",
    "    train = ts[:-step]  # –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
    "    test = ts[-step:]   # –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
    "\n",
    "    for comb in abg:\n",
    "        try:\n",
    "            model = ExponentialSmoothing(train, trend=\"add\", seasonal=\"add\", seasonal_periods=12)\n",
    "            fitted_model = model.fit(smoothing_level=comb[0], smoothing_slope=comb[1], smoothing_seasonal=comb[2])\n",
    "            y_pred = fitted_model.forecast(step)\n",
    "            mae = mean_absolute_error(test, y_pred)\n",
    "\n",
    "            if mae < best_mae:\n",
    "                best_alpha, best_beta, best_gamma, best_mae = comb[0], comb[1], comb[2], mae\n",
    "\n",
    "        except Exception as e:\n",
    "            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏\n",
    "            continue\n",
    "\n",
    "    return best_alpha, best_beta, best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab0ad56-a2f7-429f-bb81-11b1f4004a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2577/2577 [14:43<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "forecast_list = []\n",
    "groups = list(df_full.groupby([\"–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞\", \"–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü\", \"–ê—Ä—Ç–∏–∫—É–ª\"]))\n",
    "total_groups = len(groups)  # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä—É–ø–ø –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "number_of_periods = 6\n",
    "\n",
    "# –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º tqdm\n",
    "for (group, mp, article), group_data in tqdm(groups, total=total_groups, desc=\"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ\"):\n",
    "    # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –ø–æ –¥–∞—Ç–µ\n",
    "    group_data = group_data.sort_values(\"–î–∞—Ç–∞\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥\n",
    "    ts = group_data.set_index(\"–î–∞—Ç–∞\")[\"–û—Ç–≥—Ä—É–∂–µ–Ω–æ, —à—Ç.\"]\n",
    "    \n",
    "    # –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É\n",
    "    current_date = pd.Timestamp.now()\n",
    "    \n",
    "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ–Ω—å —Ä–∞–≤–Ω—ã–º 1 –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π Timestamp\n",
    "    first_day_of_current_month = current_date.replace(day=1)\n",
    "\n",
    "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ–Ω—å —Ä–∞–≤–Ω—ã–º 1 –∏ –¥–æ–±–∞–≤–ª—è–µ–º 1 –º–µ—Å—è—Ü\n",
    "    first_day_of_next_month = (current_date.replace(day=1) + pd.offsets.MonthBegin(1))\n",
    "\n",
    "    start_date = first_day_of_next_month  #first_day_of_current_month  # –ü–µ—Ä–≤—ã–π –¥–µ–Ω—å —Ç–µ–∫—É—â–µ–≥–æ –∏–ª–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –º–µ—Å—è—Ü–∞\n",
    "\n",
    "    forecast_index_future = pd.date_range(start=start_date, periods=number_of_periods, freq=\"MS\")\n",
    "    forecast_index_past = pd.date_range(end=start_date - pd.DateOffset(months=1), periods=number_of_periods, freq=\"MS\")\n",
    "    \n",
    "    try:\n",
    "        if len(ts) >= 24+number_of_periods:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–ª–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "            \n",
    "            # –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤–∫–ª—é—á–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã)\n",
    "            forecast_values_future = []\n",
    "            history = ts.copy()\n",
    "            for _ in range(number_of_periods):\n",
    "                model = ExponentialSmoothing(history, trend=\"add\", seasonal=\"add\", seasonal_periods=12)\n",
    "                fitted_model = model.fit() \n",
    "                next_forecast = fitted_model.forecast(1)[0]\n",
    "                forecast_values_future.append(next_forecast)\n",
    "                \n",
    "                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å –Ω–æ–≤—ã–º –ø—Ä–æ–≥–Ω–æ–∑–æ–º\n",
    "                new_index = history.index[-1] + pd.offsets.MonthBegin()\n",
    "                history = pd.concat([history, pd.Series(next_forecast, index=[new_index])])\n",
    "\n",
    "            # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–∑–∞–¥ —Å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ number_of_periods –º–µ—Å—è—Ü–∞–º–∏\n",
    "            truncated_history = ts.iloc[:-number_of_periods].copy()  # –û–±—Ä–µ–∑–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Å—è—Ü—ã\n",
    "            forecast_values_past = []\n",
    "            for i in range(number_of_periods):\n",
    "                model = ExponentialSmoothing(truncated_history, trend=\"add\", seasonal=\"add\", seasonal_periods=12)\n",
    "                fitted_model = model.fit()\n",
    "                prev_forecast = fitted_model.forecast(1)[0]\n",
    "                forecast_values_past.append(prev_forecast)\n",
    "                \n",
    "                # –í–º–µ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ, –∫–æ—Ç–æ—Ä–æ–µ —É–±—Ä–∞–ª–∏ —Ä–∞–Ω–µ–µ\n",
    "                actual_value = ts.iloc[-number_of_periods + i]  # –ë–µ—Ä–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "                new_index = ts.index[-number_of_periods + i]  # –ï–≥–æ –∏–Ω–¥–µ–∫—Å\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏\n",
    "                truncated_history = pd.concat([truncated_history, pd.Series(actual_value, index=[new_index])])\n",
    "\n",
    "        elif len(ts) >= 18+number_of_periods:  # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, –Ω–∞–∑–∞–¥ - –º–µ–Ω—å—à–µ 24\n",
    "\n",
    "            # –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤–∫–ª—é—á–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã)\n",
    "            forecast_values_future = []\n",
    "            history = ts.copy()\n",
    "            for _ in range(number_of_periods):\n",
    "                model = ExponentialSmoothing(history, trend=\"add\", seasonal=\"add\", seasonal_periods=12)\n",
    "                fitted_model = model.fit() \n",
    "                next_forecast = fitted_model.forecast(1)[0]\n",
    "                forecast_values_future.append(next_forecast)\n",
    "                \n",
    "                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å –Ω–æ–≤—ã–º –ø—Ä–æ–≥–Ω–æ–∑–æ–º\n",
    "                new_index = history.index[-1] + pd.offsets.MonthBegin()\n",
    "                history = pd.concat([history, pd.Series(next_forecast, index=[new_index])])\n",
    "\n",
    "            # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–∑–∞–¥ —Å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ number_of_periods –º–µ—Å—è—Ü–∞–º–∏\n",
    "            truncated_history = ts.iloc[:-number_of_periods].copy()\n",
    "            forecast_values_past = []\n",
    "            for i in range(number_of_periods):\n",
    "                model = ExponentialSmoothing(truncated_history, trend=\"add\", seasonal=None)\n",
    "                fitted_model = model.fit()\n",
    "                prev_forecast = fitted_model.forecast(1)[0]\n",
    "                forecast_values_past.append(prev_forecast)\n",
    "                \n",
    "                # –í–º–µ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ, –∫–æ—Ç–æ—Ä–æ–µ —É–±—Ä–∞–ª–∏ —Ä–∞–Ω–µ–µ\n",
    "                actual_value = ts.iloc[-number_of_periods + i]  # –ë–µ—Ä–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "                new_index = ts.index[-number_of_periods + i]  # –ï–≥–æ –∏–Ω–¥–µ–∫—Å\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏\n",
    "                truncated_history = pd.concat([truncated_history, pd.Series(actual_value, index=[new_index])])\n",
    "        \n",
    "        elif len(ts) >= 12+number_of_periods:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–µ–Ω–¥–æ–≤–æ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "            # –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤–∫–ª—é—á–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã)\n",
    "            forecast_values_future = []\n",
    "            history = ts.copy()\n",
    "            for _ in range(number_of_periods):\n",
    "                model = ExponentialSmoothing(history, trend=\"add\", seasonal=None)\n",
    "                fitted_model = model.fit() \n",
    "                next_forecast = fitted_model.forecast(1)[0] \n",
    "                forecast_values_future.append(next_forecast)\n",
    "                \n",
    "                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å –Ω–æ–≤—ã–º –ø—Ä–æ–≥–Ω–æ–∑–æ–º\n",
    "                new_index = history.index[-1] + pd.offsets.MonthBegin()\n",
    "                history = pd.concat([history, pd.Series(next_forecast, index=[new_index])])\n",
    "\n",
    "            # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–∑–∞–¥ —Å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ number_of_periods –º–µ—Å—è—Ü–∞–º–∏\n",
    "            truncated_history = ts.iloc[:-number_of_periods].copy()\n",
    "            forecast_values_past = []\n",
    "            for i in range(number_of_periods):\n",
    "                model = ExponentialSmoothing(truncated_history, trend=\"add\", seasonal=None)\n",
    "                fitted_model = model.fit()\n",
    "                prev_forecast = fitted_model.forecast(1)[0]\n",
    "                forecast_values_past.append(prev_forecast)\n",
    "                \n",
    "                # –í–º–µ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ, –∫–æ—Ç–æ—Ä–æ–µ —É–±—Ä–∞–ª–∏ —Ä–∞–Ω–µ–µ\n",
    "                actual_value = ts.iloc[-number_of_periods + i]  # –ë–µ—Ä–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "                new_index = ts.index[-number_of_periods + i]  # –ï–≥–æ –∏–Ω–¥–µ–∫—Å\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏\n",
    "                truncated_history = pd.concat([truncated_history, pd.Series(actual_value, index=[new_index])])\n",
    "\n",
    "        elif len(ts) >= 6+number_of_periods:  # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, –Ω–∞–∑–∞–¥ - –º–µ–Ω—å—à–µ 12\n",
    "\n",
    "            # –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤–∫–ª—é—á–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã)\n",
    "            forecast_values_future = []\n",
    "            history = ts.copy()\n",
    "            for _ in range(number_of_periods):\n",
    "                model = ExponentialSmoothing(history, trend=\"add\", seasonal=None)\n",
    "                fitted_model = model.fit() \n",
    "                next_forecast = fitted_model.forecast(1)[0] \n",
    "                forecast_values_future.append(next_forecast)\n",
    "                \n",
    "                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å –Ω–æ–≤—ã–º –ø—Ä–æ–≥–Ω–æ–∑–æ–º\n",
    "                new_index = history.index[-1] + pd.offsets.MonthBegin()\n",
    "                history = pd.concat([history, pd.Series(next_forecast, index=[new_index])])\n",
    "\n",
    "            # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–∑–∞–¥ —Å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ number_of_periods –º–µ—Å—è—Ü–∞–º–∏\n",
    "            truncated_history = ts.iloc[:-number_of_periods].copy()\n",
    "            forecast_values_past = []\n",
    "            for i in range(number_of_periods):\n",
    "                weighted_mean = (truncated_history * range(1, len(truncated_history) + 1)).sum() / sum(range(1, len(truncated_history) + 1))\n",
    "                forecast_values_past.append(weighted_mean)\n",
    "                \n",
    "                # –í–º–µ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ, –∫–æ—Ç–æ—Ä–æ–µ —É–±—Ä–∞–ª–∏ —Ä–∞–Ω–µ–µ\n",
    "                actual_value = ts.iloc[-number_of_periods + i]  # –ë–µ—Ä–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "                new_index = ts.index[-number_of_periods + i]  # –ï–≥–æ –∏–Ω–¥–µ–∫—Å\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏\n",
    "                truncated_history = pd.concat([truncated_history, pd.Series(actual_value, index=[new_index])])\n",
    "\n",
    "        else:\n",
    "            forecast_values_future = [].copy()\n",
    "            history = ts.copy()\n",
    "            for _ in range(number_of_periods):\n",
    "                weights = range(1, len(history) + 1)\n",
    "                weighted_mean = (history * weights).sum() / sum(weights)\n",
    "                forecast_values_future.append(weighted_mean)\n",
    "                history = history.append(pd.Series(weighted_mean, index=[history.index[-1] + pd.offsets.MonthBegin()]))\n",
    "            \n",
    "            truncated_history = ts.iloc[:-number_of_periods]\n",
    "            forecast_values_past = []\n",
    "            for i in range(number_of_periods):\n",
    "                weighted_mean = (truncated_history * range(1, len(truncated_history) + 1)).sum() / sum(range(1, len(truncated_history) + 1))\n",
    "                forecast_values_past.append(weighted_mean)\n",
    "                \n",
    "                # –í–º–µ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ, –∫–æ—Ç–æ—Ä–æ–µ —É–±—Ä–∞–ª–∏ —Ä–∞–Ω–µ–µ\n",
    "                actual_value = ts.iloc[-number_of_periods + i]  # –ë–µ—Ä–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "                new_index = ts.index[-number_of_periods + i]  # –ï–≥–æ –∏–Ω–¥–µ–∫—Å\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏\n",
    "                truncated_history = pd.concat([truncated_history, pd.Series(actual_value, index=[new_index])])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥—Ä—É–ø–ø—ã {group}, –∞—Ä—Ç–∏–∫—É–ª–∞ {article}: {e}\")\n",
    "        # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏\n",
    "        forecast_values_future = [0] * number_of_periods\n",
    "        forecast_values_past = [0] * number_of_periods\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "    forecast_future_df = pd.DataFrame({\n",
    "        \"–î–∞—Ç–∞\": forecast_index_future,\n",
    "        \"–ì–æ–¥\": forecast_index_future.year,\n",
    "        \"–ö–≤–∞—Ä—Ç–∞–ª\": ((forecast_index_future.month - 1) // 3 + 1),\n",
    "        \"–ú–µ—Å—è—Ü\": forecast_index_future.month,\n",
    "        \"–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞\": group,\n",
    "        \"–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü\": mp,\n",
    "        \"–ö–æ–¥\": group_data[\"–ö–æ–¥\"].iloc[0],\n",
    "        \"–ê—Ä—Ç–∏–∫—É–ª\": article,\n",
    "        \"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\": group_data[\"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\"].iloc[0],\n",
    "        \"–ì—Ä—É–ø–ø–∞\": group_data[\"–ì—Ä—É–ø–ø–∞\"].iloc[0],\n",
    "        \"–û—Ç–≥—Ä—É–∂–µ–Ω–æ, —à—Ç.\": forecast_values_future,\n",
    "        \"–¶–µ–Ω–∞, —Ä—É–±.\": group_data[\"–¶–µ–Ω–∞, —Ä—É–±.\"].iloc[0],\n",
    "        \"–í–µ—Å, –∫–≥.\": group_data[\"–í–µ—Å, –∫–≥.\"].iloc[0],\n",
    "        \"–í–∏–¥ —Å—ã—Ä—å—è\": group_data[\"–í–∏–¥ —Å—ã—Ä—å—è\"].iloc[0],\n",
    "        \"–ò—Å—Ç–æ—Ä–∏—è/–ü—Ä–æ–≥–Ω–æ–∑\": \"–ü—Ä–æ–≥–Ω–æ–∑ –≤–ø–µ—Ä–µ–¥\"\n",
    "    })\n",
    "\n",
    "    forecast_past_df = pd.DataFrame({\n",
    "        \"–î–∞—Ç–∞\": forecast_index_past,\n",
    "        \"–ì–æ–¥\": forecast_index_past.year,\n",
    "        \"–ö–≤–∞—Ä—Ç–∞–ª\": ((forecast_index_past.month - 1) // 3 + 1),\n",
    "        \"–ú–µ—Å—è—Ü\": forecast_index_past.month,\n",
    "        \"–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞\": group,\n",
    "        \"–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü\": mp,\n",
    "        \"–ö–æ–¥\": group_data[\"–ö–æ–¥\"].iloc[0],\n",
    "        \"–ê—Ä—Ç–∏–∫—É–ª\": article,\n",
    "        \"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\": group_data[\"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\"].iloc[0],\n",
    "        \"–ì—Ä—É–ø–ø–∞\": group_data[\"–ì—Ä—É–ø–ø–∞\"].iloc[0],\n",
    "        \"–û—Ç–≥—Ä—É–∂–µ–Ω–æ, —à—Ç.\": forecast_values_past,\n",
    "        \"–¶–µ–Ω–∞, —Ä—É–±.\": group_data[\"–¶–µ–Ω–∞, —Ä—É–±.\"].iloc[0],\n",
    "        \"–í–µ—Å, –∫–≥.\": group_data[\"–í–µ—Å, –∫–≥.\"].iloc[0],\n",
    "        \"–í–∏–¥ —Å—ã—Ä—å—è\": group_data[\"–í–∏–¥ —Å—ã—Ä—å—è\"].iloc[0],\n",
    "        \"–ò—Å—Ç–æ—Ä–∏—è/–ü—Ä–æ–≥–Ω–æ–∑\": \"–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–∑–∞–¥\"\n",
    "        \n",
    "    })\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –≤ —Å–ø–∏—Å–æ–∫\n",
    "    forecast_list.append(forecast_future_df)\n",
    "    forecast_list.append(forecast_past_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e667a-71fa-4a37-9a67-be4f3b0100a0",
   "metadata": {},
   "source": [
    "## üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98715492-fc56-4429-81ae-0b5a9d8d5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã\n",
    "forecast_result = pd.concat(forecast_list, ignore_index=True)\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º\n",
    "df[\"–ò—Å—Ç–æ—Ä–∏—è/–ü—Ä–æ–≥–Ω–æ–∑\"] = \"–ò—Å—Ç–æ—Ä–∏—è\"\n",
    "result_df = pd.concat([df, forecast_result], ignore_index=True)\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ\n",
    "result_df = result_df.sort_values([\"–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞\", \"–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü\", \"–ê—Ä—Ç–∏–∫—É–ª\", \"–î–∞—Ç–∞\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a0dca5-d1d7-42d5-9670-de599f3e3db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–≥–Ω–æ–∑ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ü—Ä–æ–≥–Ω–æ–∑_—Å_–∏—Å—Ç–æ—Ä–∏–µ–π.xlsx\n"
     ]
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ\n",
    "result_df = result_df.sort_values([\"–ì—Ä—É–ø–ø–∞ –∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞\", \"–ü—Ä–æ–¥–∞–µ—Ç –Ω–∞ –ú–ü\", \"–ê—Ä—Ç–∏–∫—É–ª\", \"–î–∞—Ç–∞\"])\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
    "output_path = \"–ü—Ä–æ–≥–Ω–æ–∑_—Å_–∏—Å—Ç–æ—Ä–∏–µ–π.xlsx\"\n",
    "result_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"–ü—Ä–æ–≥–Ω–æ–∑ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
